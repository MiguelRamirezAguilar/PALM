{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767150e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "import os\n",
    "import joblib\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,roc_auc_score,accuracy_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from time import time\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from time import time\n",
    "from timeit import default_timer as timer\n",
    "#start = timer()\n",
    "#end = timer()\n",
    "#print(end - start) \n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sampling(original_features, original_labels):\n",
    "\n",
    "    X = original_features\n",
    "    y = original_labels\n",
    "    undersample = RandomUnderSampler(sampling_strategy=0.8)\n",
    "    X_under, y_under = undersample.fit_resample(X, y)\n",
    "    malware_undersampled = X_under\n",
    "    malware_undersampled['Label']=y_under\n",
    "    print(f\"Count after undersampling: \\n{malware_undersampled['Label'].value_counts()}\")\n",
    "    print(f\"Shape of dataset: \\n{malware_undersampled.shape}\")\n",
    "    \n",
    "    undersampled_features = malware_undersampled.drop(columns = [\"Label\"])\n",
    "    undersampled_labels = malware_undersampled.Label\n",
    "\n",
    "    return undersampled_features, undersampled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        title = 'Confusion matrix'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "  #  classes = unique_labels(y_true, y_pred)\n",
    "    print('Confusion matrix')\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_lf(labels,kpoison):    \n",
    "    z_train=labels\n",
    "    a=0;b=0; #just indicators \n",
    "    kpoison=0.5\n",
    "    rate_poison=round(kpoison*y_train.shape[0]);\n",
    "    for l in range(0,rate_poison):\n",
    "        location=random.randint(0,31410)\n",
    "        c=z_train[location];\n",
    "        if (c==0):\n",
    "            z_train[location]=1\n",
    "            a=a+1 #label-flipped samples for label 0\n",
    "        else:\n",
    "            z_train[location]=0\n",
    "            b=b+1 #label flipped samples for label 1    \n",
    "    print(f\"The number of data poisoned is the following: \\n{a+b}\\n Out of a total of: \\n{z_train.shape[0]}\")\n",
    "    #a+b=how many samples have been label flipped\n",
    "    return z_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('train_set.csv')\n",
    "test_set = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a930d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set.drop(columns = ['Label'])\n",
    "y_train = train_set.Label\n",
    "x_test = test_set.drop(columns = ['Label'])\n",
    "y_test = test_set.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The ORIGINAL label vector is the following: \\n{y_train}\")\n",
    "#y_train \n",
    "print(f\"Shape of LABEL VECTOR: \\n{y_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "poison=0.5 #proportion of samples to be poisoned\n",
    "y_train=poison_lf(y_train,poison)\n",
    "print(f\"The POISONED label vector is the following: \\n{y_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest algorithm\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2094991",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = rf.predict(x_test).astype(int)\n",
    "plot_confusion_matrix(y_test, y_predicted, classes=unique_labels(y_test.astype(int), y_predicted), title='Confusion matrix')\n",
    "plt.show()\n",
    "print(f\"The accuracy is: {accuracy_score(y_test, y_predicted)}\")\n",
    "print(f\"The precision is: {precision_score(y_test, y_predicted)}\")\n",
    "print(f\"The recall is: {recall_score(y_test, y_predicted)}\")\n",
    "print(f\"The f1 score is: {f1_score(y_test, y_predicted)}\")\n",
    "print(f\"The auc score is: {roc_auc_score(y_test, y_predicted)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
